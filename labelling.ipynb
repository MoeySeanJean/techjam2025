{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6677d8c5",
   "metadata": {},
   "source": [
    "# Labelling with OpenAI GPT 5 Nano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c24972",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e706d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (1.102.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: pandas in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\.conda\\envs\\techjam2025\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai python-dotenv pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d065ce6",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e4cb293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab862d",
   "metadata": {},
   "source": [
    "## Login to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d10802b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81269ea",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba9b524",
   "metadata": {},
   "source": [
    "### kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b21b59f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n",
      "                     business_name    author_name  \\\n",
      "0  Haci'nin Yeri - Yigit Lokantasi    Gulsum Akar   \n",
      "1  Haci'nin Yeri - Yigit Lokantasi  Oguzhan Cetin   \n",
      "2  Haci'nin Yeri - Yigit Lokantasi     Yasin Kuyu   \n",
      "3  Haci'nin Yeri - Yigit Lokantasi     Orhan Kapu   \n",
      "4  Haci'nin Yeri - Yigit Lokantasi     Ozgur Sati   \n",
      "\n",
      "                                                text  \\\n",
      "0  We went to Marmaris with my wife for a holiday...   \n",
      "1  During my holiday in Marmaris we ate here to f...   \n",
      "2  Prices are very affordable. The menu in the ph...   \n",
      "3  Turkey's cheapest artisan restaurant and its f...   \n",
      "4  I don't know what you will look for in terms o...   \n",
      "\n",
      "                                               photo  rating  \\\n",
      "0         dataset/taste/hacinin_yeri_gulsum_akar.png       5   \n",
      "1        dataset/menu/hacinin_yeri_oguzhan_cetin.png       4   \n",
      "2  dataset/outdoor_atmosphere/hacinin_yeri_yasin_...       3   \n",
      "3  dataset/indoor_atmosphere/hacinin_yeri_orhan_k...       5   \n",
      "4           dataset/menu/hacinin_yeri_ozgur_sati.png       3   \n",
      "\n",
      "      rating_category  \n",
      "0               taste  \n",
      "1                menu  \n",
      "2  outdoor_atmosphere  \n",
      "3   indoor_atmosphere  \n",
      "4                menu  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/reviews.csv\")\n",
    "df = df.dropna(subset=[\"text\"]).reset_index(drop=True)\n",
    "print(len(df))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf6ad3b",
   "metadata": {},
   "source": [
    "### UCSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "eef43405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178168\n",
      "                 user_id             name           time  rating  \\\n",
      "0  118026874392842649478    rebecca kerns  1620085852324       5   \n",
      "1  101532740754036204131    Peter DeForge  1580309946474       5   \n",
      "2  115404122636203550540    Chad Goulette  1605195974445       5   \n",
      "3  104789336434407408181  Mark LaFountain  1593005848256       5   \n",
      "4  108980665975608069965           Jeff R  1582059996120       5   \n",
      "\n",
      "                                                text  pics  \\\n",
      "0      Always done right from wood stove to screens!  None   \n",
      "1  A great company to work with.  Their sales and...  None   \n",
      "2  Great place to do business with staff was grea...  None   \n",
      "3  Awesome Customer service, quick response, and ...  None   \n",
      "4  If you need a top quality job, by a group of p...  None   \n",
      "\n",
      "                                                resp  \\\n",
      "0  {'time': 1620087641504, 'text': 'Good Evening,...   \n",
      "1  {'time': 1580320228721, 'text': 'Good Afternoo...   \n",
      "2  {'time': 1605195166792, 'text': 'Hi Chad!\n",
      "\n",
      "Tha...   \n",
      "3  {'time': 1593376422014, 'text': 'Mark, thank y...   \n",
      "4  {'time': 1582063833737, 'text': 'Good Afternoo...   \n",
      "\n",
      "                                 gmap_id  \n",
      "0  0x89e02445cb9db457:0x37f42bff4edf7a43  \n",
      "1  0x89e02445cb9db457:0x37f42bff4edf7a43  \n",
      "2  0x89e02445cb9db457:0x37f42bff4edf7a43  \n",
      "3  0x89e02445cb9db457:0x37f42bff4edf7a43  \n",
      "4  0x89e02445cb9db457:0x37f42bff4edf7a43  \n"
     ]
    }
   ],
   "source": [
    "def parse(path):\n",
    "    with gzip.open(path, 'rt', encoding='utf-8') as g:\n",
    "        for line in g:\n",
    "            yield json.loads(line)\n",
    "data = list(parse(\"./data/review-Vermont_10.json.gz\"))\n",
    "df = pd.DataFrame(data)\n",
    "df = df.dropna(subset=[\"text\"]).reset_index(drop=True)\n",
    "print(len(df))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6704499b",
   "metadata": {},
   "source": [
    "## Creating prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "afb7a8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Classify this review:\\n<review>Always done rig...\n",
      "1    Classify this review:\\n<review>A great company...\n",
      "2    Classify this review:\\n<review>Great place to ...\n",
      "3    Classify this review:\\n<review>Awesome Custome...\n",
      "4    Classify this review:\\n<review>If you need a t...\n",
      "Name: prompt, dtype: object\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT_STRING = \"\"\"You are a strict moderation judge for location reviews. Classify each review into exactly ONE of:\n",
    "advertisement (self-promo, discount codes, contact links),\n",
    "irrelevant (off-topic, questions/chat unrelated to a real visit),\n",
    "rant_without_visit (angry/defamatory without evidence of an actual visit),\n",
    "clean (a normal on-topic review—positive or negative—from a real/likely visit).\n",
    "If multiple seem plausible, choose the most severe (advertisement > irrelevant > rant_without_visit > clean).\n",
    "Ignore emojis, casing, punctuation spam, and translation artifacts.\n",
    "Do not guess facts.\"\"\"\n",
    "\n",
    "schema = {\n",
    "    \"name\": \"google_reviews_label\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"label\": {\"type\":\"string\",\"enum\":[\"advertisement\",\"irrelevant\",\"rant_without_visit\",\"clean\"]}\n",
    "        },\n",
    "        \"required\": [\"label\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "df[\"prompt\"] = df[\"text\"].apply(lambda review: f\"Classify this review:\\n<review>{review}</review>\")\n",
    "print(df[\"prompt\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e86200",
   "metadata": {},
   "source": [
    "## Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "45faf5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_file = \"./data/requests.jsonl\"\n",
    "responses_file = \"./data/responses.jsonl\"\n",
    "if os.path.exists(jsonl_file):\n",
    "    os.remove(jsonl_file)\n",
    "if os.path.exists(responses_file):\n",
    "    os.remove(responses_file)\n",
    "for i in range(math.ceil(len(df)/750)):\n",
    "    with open(jsonl_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for j, prompt in enumerate(df[\"prompt\"][i * 750:(i + 1) * 750], start=1):\n",
    "            request_obj = {\n",
    "                \"custom_id\": f\"{i*750 + j}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                \"model\": \"gpt-5-nano\",\n",
    "                \"messages\": [\n",
    "                        {\"role\":\"system\",\"content\": SYSTEM_PROMPT_STRING},\n",
    "                        {\"role\":\"user\",\"content\": prompt}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "            f.write(json.dumps(request_obj) + \"\\n\")\n",
    "    batch_input_file = client.files.create(\n",
    "        file=open(jsonl_file, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "    batch = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": \"nightly eval job\"\n",
    "        }\n",
    "    )\n",
    "    batch_id = batch.id\n",
    "    batch = client.batches.retrieve(batch_id)\n",
    "    while (batch.status != \"completed\"):\n",
    "        time.sleep(5)\n",
    "        batch = client.batches.retrieve(batch_id)\n",
    "    file_response = client.files.content(batch.output_file_id)\n",
    "    with open(responses_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(file_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d12b04c",
   "metadata": {},
   "source": [
    "## Save to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f61de82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 user_id             name           time  rating  \\\n",
      "0  118026874392842649478    rebecca kerns  1620085852324       5   \n",
      "1  101532740754036204131    Peter DeForge  1580309946474       5   \n",
      "2  115404122636203550540    Chad Goulette  1605195974445       5   \n",
      "3  104789336434407408181  Mark LaFountain  1593005848256       5   \n",
      "4  108980665975608069965           Jeff R  1582059996120       5   \n",
      "\n",
      "                                                text  pics  \\\n",
      "0      Always done right from wood stove to screens!  None   \n",
      "1  A great company to work with.  Their sales and...  None   \n",
      "2  Great place to do business with staff was grea...  None   \n",
      "3  Awesome Customer service, quick response, and ...  None   \n",
      "4  If you need a top quality job, by a group of p...  None   \n",
      "\n",
      "                                                resp  \\\n",
      "0  {'time': 1620087641504, 'text': 'Good Evening,...   \n",
      "1  {'time': 1580320228721, 'text': 'Good Afternoo...   \n",
      "2  {'time': 1605195166792, 'text': 'Hi Chad!\n",
      "\n",
      "Tha...   \n",
      "3  {'time': 1593376422014, 'text': 'Mark, thank y...   \n",
      "4  {'time': 1582063833737, 'text': 'Good Afternoo...   \n",
      "\n",
      "                                 gmap_id  label  \n",
      "0  0x89e02445cb9db457:0x37f42bff4edf7a43  clean  \n",
      "1  0x89e02445cb9db457:0x37f42bff4edf7a43  clean  \n",
      "2  0x89e02445cb9db457:0x37f42bff4edf7a43  clean  \n",
      "3  0x89e02445cb9db457:0x37f42bff4edf7a43  clean  \n",
      "4  0x89e02445cb9db457:0x37f42bff4edf7a43  clean  \n"
     ]
    }
   ],
   "source": [
    "df_responses = pd.read_json(responses_file, lines=True)\n",
    "df[\"label\"] = df_responses[\"response\"].apply(lambda x: x['body']['choices'][0]['message']['content'])\n",
    "df.to_csv(\"./data/review-Vermont_10-labeled.csv\", index=False)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab8f883",
   "metadata": {},
   "source": [
    "## Change label to 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f3ca749e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moey Sean Jean\\AppData\\Local\\Temp\\ipykernel_9484\\1943313882.py:1: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"./data/review-Vermont_10-labeled.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0      Always done right from wood stove to screens!      0\n",
      "1  A great company to work with.  Their sales and...      0\n",
      "2  Great place to do business with staff was grea...      0\n",
      "3  Awesome Customer service, quick response, and ...      0\n",
      "4  If you need a top quality job, by a group of p...      0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/review-Vermont_10-labeled.csv\")\n",
    "df['label'] = df['label'].apply(lambda x: 0 if str(x).lower() == \"clean\" else 1)\n",
    "df = df[['text', 'label']]\n",
    "df.to_csv(\"./data/review-Vermont_10-binary.csv\", index=False)\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "techjam2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
