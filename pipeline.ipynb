{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87dd6886",
   "metadata": {},
   "source": [
    "# Solution pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0712600",
   "metadata": {},
   "source": [
    "This solution pipeline contains a call to Google Translate to translate the review, then the translated text is classified into flagged or clean with our model. If the review is empty text, it will be flagged as discussed in `README.md`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3248d22",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6657f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers datasets pandas scikit-learn googletrans\n",
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu129"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ff4612",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46998e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b0c699",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d014ae9e",
   "metadata": {},
   "source": [
    "This is to load the trained model from training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4aa3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./data/saved_model\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForSequenceClassification.from_pretrained(save_dir, local_files_only=True)\n",
    "model.to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(save_dir, local_files_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e22c5b",
   "metadata": {},
   "source": [
    "## Load testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc49aa23",
   "metadata": {},
   "source": [
    "For testing and evaluation of our model, we used 2 datasets. One is scrapped and labelled manually from local (Singapore) Google Maps reviews. The other is Kaggle dataset as mentioned in `README.md`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f148ed",
   "metadata": {},
   "source": [
    "### Local (Singapore) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0107063",
   "metadata": {},
   "source": [
    "This data is manually scrapped and labelled from Google Maps directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce8abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/test-data-labeled.csv\")\n",
    "df = df[['text', 'label']]\n",
    "df = df.dropna(subset=[\"text\"]).reset_index(drop=True)\n",
    "\n",
    "texts = df['text'].to_list()\n",
    "indices = []\n",
    "texts_to_translate = []\n",
    "translated_texts = texts.copy()\n",
    "async def translate_bulk():\n",
    "    async with Translator() as translator:\n",
    "        for index, text in enumerate(texts):\n",
    "            result = await translator.detect(text)\n",
    "            if result.lang != 'en':\n",
    "                indices.append(index)\n",
    "                texts_to_translate.append(text)\n",
    "        translations = await translator.translate(texts_to_translate)\n",
    "        for i, translation in zip(indices, translations):\n",
    "            translated_texts[i] = translation.text\n",
    "await translate_bulk()\n",
    "df['text'] = translated_texts\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "test_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"], \n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "tokenized_dataset = test_dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "tokenized_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(tokenized_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac5c691",
   "metadata": {},
   "source": [
    "### Kaggle data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2e76d9",
   "metadata": {},
   "source": [
    "This data is from kaggle (see `README.md`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0249e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/reviews-labeled.csv\")\n",
    "df = df[['text', 'label']]\n",
    "df = df.dropna(subset=[\"text\"]).reset_index(drop=True)\n",
    "df['label'] = df['label'].apply(lambda x : 0 if x == \"clean\" else 1)\n",
    "\n",
    "test_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"], \n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "tokenized_dataset = test_dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "tokenized_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(tokenized_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0583cfe8",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a79d6c8",
   "metadata": {},
   "source": [
    "This will run evaluation on test dataset as well as calculate the accuracy, precision, recall and f1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c390c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    all_labels, all_preds, average=\"weighted\"\n",
    ")\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "precision_cls, recall_cls, f1_cls, support_cls = precision_recall_fscore_support(\n",
    "    all_labels, all_preds, labels=[0,1], average=None\n",
    ")\n",
    "\n",
    "print(\"Class-wise metrics:\")\n",
    "for i, (p, r, f, s) in enumerate(zip(precision_cls, recall_cls, f1_cls, support_cls)):\n",
    "    print(f\"Class {i} -> Precision: {p:.4f}, Recall: {r:.4f}, F1: {f:.4f}, Support: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf26682b",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c8f1c",
   "metadata": {},
   "source": [
    "Full pipeline for our solution. Place real-world reviews in `reviews` and run the cell. It will print the prediction of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca27c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"My Roblox account got hacked from this location\",\n",
    "    \"I hear this is a top university I wanna go here\",\n",
    "    \"Amazing place for students worldwide. Top notch facilities for everything you care about. Really interesting lot of students to hang around. You'll love this space, the Campus is attracted all over the city of Singapore. For vegetarians, it's a bit tricky to get the desired food. Amazing public transport and AQI less than 50.\",\n",
    "    \"真他妈的好吃，推荐他们的辣子鸡\",\n",
    "    \"restoran ini ada nasi lemak yang terbaik di seluruh Malaysia\",\n",
    "    \"\"\n",
    "]\n",
    "df = pd.DataFrame(reviews, columns=['text'])\n",
    "\n",
    "texts = df['text'].to_list()\n",
    "indices = []\n",
    "texts_to_translate = []\n",
    "translated_texts = texts.copy()\n",
    "async def translate_bulk():\n",
    "    async with Translator() as translator:\n",
    "        for index, text in enumerate(texts):\n",
    "            result = await translator.detect(text)\n",
    "            if result.lang != 'en':\n",
    "                indices.append(index)\n",
    "                texts_to_translate.append(text)\n",
    "        translations = await translator.translate(texts_to_translate)\n",
    "        for i, translation in zip(indices, translations):\n",
    "            translated_texts[i] = translation.text\n",
    "await translate_bulk()\n",
    "df['text'] = translated_texts\n",
    "\n",
    "results = [\"\"] * len(df)\n",
    "non_empty_indices = [i for i, r in enumerate(df['text']) if r.strip()]\n",
    "non_empty_texts = [df['text'][i] for i in non_empty_indices]\n",
    "if non_empty_texts:\n",
    "    inputs = tokenizer(non_empty_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "    for idx, pred in zip(non_empty_indices, predictions):\n",
    "        results[idx] = \"clean\" if pred.item() == 0 else \"flagged\"\n",
    "for i, r in enumerate(df['text']):\n",
    "    if not r.strip():\n",
    "        results[i] = \"flagged\"\n",
    "df[\"label\"] = results\n",
    "for review, label in zip(df['text'], df['label']):\n",
    "    print(f\"Review: {review}\\nPredicted label: {label}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "techjam2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
