{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 50 startUrls\n",
      "Wrote clementi_places_deduped.json with 50 startUrls.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"dataset_crawler-google-places_2025-08-28_15-58-50-060.json\") as f:\n",
    "    places = json.load(f)\n",
    "\n",
    "startUrls = []\n",
    "for p in places:\n",
    "    pid = p.get(\"placeId\")\n",
    "    url = p.get(\"url\")\n",
    "    if pid:\n",
    "        startUrls.append({\"url\": f\"https://www.google.com/maps/place/?q=place_id:{pid}\"})\n",
    "    elif url:\n",
    "        startUrls.append({\"url\": url})\n",
    "\n",
    "print(f\"Built {len(startUrls)} startUrls\")\n",
    "\n",
    "out = {\n",
    "    \"startUrls\": startUrls,\n",
    "    \"maxReviews\": 0,\n",
    "    \"reviewsSort\": \"newest\",\n",
    "    \"language\": \"en\"\n",
    "}\n",
    "\n",
    "with open(\"clementi_places_deduped.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(out, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Wrote {\"clementi_places_deduped.json\"} with {len(startUrls)} startUrls.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 3120 | After dedupe: 643\n",
      "✔ Saved JSON -> restaurants_dedup_startUrls.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json, re, unicodedata\n",
    "import urllib.parse as urlq\n",
    "\n",
    "# === EDIT THESE to match your CSV ===\n",
    "CSV_IN = \"google_reviews_singapore.csv\"\n",
    "COL_NAME = \"place_name\"          # restaurant name\n",
    "COL_PLACEID = \"place_id\"   # Google place_id (if available)\n",
    "COL_ADDR = \"address\"       # optional: street/address column (or set to None)\n",
    "COL_URL = None             # optional: if you already have a Google Maps URL column\n",
    "\n",
    "# === 1) load ===\n",
    "df = pd.read_csv(CSV_IN)\n",
    "\n",
    "# === 2) build a normalized name for fuzzy dedupe (used when place_id is missing) ===\n",
    "def normalize(s: str) -> str:\n",
    "    if not isinstance(s, str): s = \"\"\n",
    "    # fold unicode (é -> e), lowercase, remove punctuation/spaces runs\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s)            # drop punctuation\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()        # collapse spaces\n",
    "    return s\n",
    "\n",
    "df[\"_name_norm\"] = df[COL_NAME].map(normalize)\n",
    "\n",
    "if COL_ADDR and COL_ADDR in df.columns:\n",
    "    df[\"_addr_norm\"] = df[COL_ADDR].map(normalize)\n",
    "else:\n",
    "    df[\"_addr_norm\"] = \"\"\n",
    "\n",
    "# A composite key when place_id is missing\n",
    "df[\"_fallback_key\"] = df[\"_name_norm\"] + \" | \" + df[\"_addr_norm\"]\n",
    "\n",
    "# === 3) choose a dedupe key: prefer place_id, else normalized name+address ===\n",
    "def dedupe_key(row):\n",
    "    pid = str(row.get(COL_PLACEID, \"\")).strip() if COL_PLACEID in row else \"\"\n",
    "    if pid and pid.lower() != \"nan\":\n",
    "        return (\"PID\", pid)\n",
    "    return (\"FALLBACK\", row[\"_fallback_key\"])\n",
    "\n",
    "df[\"_dedupe_key\"] = df.apply(dedupe_key, axis=1)\n",
    "\n",
    "# === 4) decide which duplicate to keep ===\n",
    "# Strategy A (simple): keep the first occurrence\n",
    "# If you have a \"reviews_count\" column and want the most-reviewed, use idxmax per group instead.\n",
    "\n",
    "# Simple keep-first:\n",
    "dedup = df.drop_duplicates(subset=[\"_dedupe_key\"], keep=\"first\").copy()\n",
    "\n",
    "# # If you prefer \"most reviews wins\", uncomment and set the column name:\n",
    "# SCORE_COL = \"reviews_count\"   # <- change to your column if you have one\n",
    "# dedup = (df.loc[df.groupby(\"_dedupe_key\")[SCORE_COL].idxmax()]\n",
    "#            if SCORE_COL in df.columns else df.drop_duplicates(\"_dedupe_key\"))\n",
    "\n",
    "print(f\"Original rows: {len(df)} | After dedupe: {len(dedup)}\")\n",
    "\n",
    "# === 5) (optional) create Google Maps URL if you need the startUrls JSON next ===\n",
    "def build_gmaps_url(name, place_id=None, url_from_csv=None):\n",
    "    if url_from_csv:              # if your CSV already has a URL, use it\n",
    "        return url_from_csv\n",
    "    if place_id and str(place_id).strip().lower() != \"nan\":\n",
    "        return f\"https://www.google.com/maps/search/?api=1&query={urlq.quote(str(name))}&query_place_id={place_id}\"\n",
    "    # no place_id: still make a searchable URL with just the name\n",
    "    return f\"https://www.google.com/maps/search/?api=1&query={urlq.quote(str(name))}\"\n",
    "\n",
    "dedup[\"gmaps_url\"] = dedup.apply(\n",
    "    lambda r: build_gmaps_url(\n",
    "        r.get(COL_NAME, \"\"),\n",
    "        r.get(COL_PLACEID, \"\") if COL_PLACEID in dedup.columns else None,\n",
    "        r.get(COL_URL, \"\") if (COL_URL and COL_URL in dedup.columns) else None\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# If you also want the JSON like your second file:\n",
    "start_urls = [{\"url\": u} for u in dedup[\"gmaps_url\"]]\n",
    "json_obj = {\n",
    "    \"startUrls\": start_urls,\n",
    "    \"maxReviews\": 0,\n",
    "    \"reviewsSort\": \"newest\",\n",
    "    \"language\": \"en\"\n",
    "}\n",
    "with open(\"restaurants_dedup_startUrls.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_obj, f, indent=2, ensure_ascii=False)\n",
    "print(\"✔ Saved JSON -> restaurants_dedup_startUrls.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
